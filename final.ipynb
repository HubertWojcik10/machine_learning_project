{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final document with all the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dt \n",
    "#import cnn \n",
    "import nn \n",
    "from load_data import load_data\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefigs = True\n",
    "if savefigs:\n",
    "    if not os.path.isdir('figs'):\n",
    "        os.makedirs('figs')\n",
    "\n",
    "\n",
    "#if savefigs: plt.savefig('../figs/DegreeDistribution.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid', palette=\"flare\")\n",
    "NAMES = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Shirt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_y_distribution(y, t):\n",
    "    ''' Plot the distribution of the labels '''\n",
    "    classes, classes_counts = np.unique(y, return_counts=True)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.barplot(x=classes, y=classes_counts, ax=ax);\n",
    "    ax.set_title(f'Class distribution of {t}', fontsize=16, fontweight='bold');\n",
    "    ax.set_ylabel('Count');\n",
    "    ax.set_xticklabels(NAMES);\n",
    "\n",
    "\n",
    "\n",
    "plot_y_distribution(y_train, \"Training data set\")\n",
    "#if savefigs: plt.savefig('figs/distributiontrainingdataset.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_y_distribution(y_test, \"Test data set\")\n",
    "#if savefigs: plt.savefig('figs/distributiontestdataset.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(X, y, measure='mean'):\n",
    "    ''' Plot the mean, median, or std of the images'''\n",
    "    classes = np.unique(y)\n",
    "    fig, ax = plt.subplots(1, len(classes), figsize=(20, 8))\n",
    "    for c in classes:\n",
    "        imgs = X[y == c]\n",
    "\n",
    "        if measure == 'mean': av_img = np.mean(imgs, axis=0).reshape(28, 28)\n",
    "        elif measure == 'median': av_img = np.median(imgs, axis=0).reshape(28, 28)\n",
    "        elif measure == 'std': av_img = np.std(imgs, axis=0).reshape(28, 28)\n",
    "\n",
    "        ax[c].imshow(av_img, cmap='gray')\n",
    "        ax[c].set_title(NAMES[c], fontsize=16, fontweight='bold')\n",
    "\n",
    "\n",
    "plot_images(X_train, y_train)\n",
    "#if savefigs: plt.savefig('figs/mean.png', bbox_inches = 'tight')\n",
    "plot_images(X_train, y_train, measure='std')\n",
    "#if savefigs: plt.savefig('figs/std.png', bbox_inches = 'tight')\n",
    "plot_images(X_train, y_train, measure='median')\n",
    "#if savefigs: plt.savefig('figs/median.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_color_distribution(X, y):\n",
    "    ''' Plot the distribution of the colors '''\n",
    "    classes = np.unique(y)\n",
    "    av_imgs = np.zeros((len(classes), 28, 28))\n",
    "    for c in classes:\n",
    "        imgs = X[y == c]\n",
    "        av_imgs[c] = np.mean(imgs, axis=0).reshape(28, 28)\n",
    "\n",
    "    #plot the distribution of the average image\n",
    "    fig, ax = plt.subplots(1, len(classes), figsize=(30, 6))\n",
    "    for c in classes:\n",
    "        sns.histplot(av_imgs[c].flatten(), ax=ax[c], kde=True)\n",
    "        ax[c].set_title(NAMES[c], fontsize=16, fontweight='bold')\n",
    "        ax[c].set_xlabel('Pixel value')\n",
    "        ax[c].set_ylabel('Count')\n",
    "\n",
    "plot_color_distribution(X_train, y_train)\n",
    "#if savefigs: plt.savefig('figs/colordistribution.png', bbox_inches = 'tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(data, labels, activationfunction):\n",
    "    fig, axes = plt.subplots(1,2, figsize = (20, 5))\n",
    "    for i, label in enumerate(labels):\n",
    "        colors_taratt = ['#761878', '#826fc9', '#b1c2f0' ]\n",
    "        sns.lineplot(x = 'epoch', y = label, palette = colors_taratt, data = data, ax = axes.flat[i]);\n",
    "        axes.flat[i].set_title(f' History of {label} with {activationfunction}', size = 13)\n",
    "        axes.flat[i].set(ylabel= f'{label}', xlabel = 'Number of epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_leakyrelu = nn.NeuralNetwork(test=True, activation_name='leaky_relu')\n",
    "df_leakyrelu = nn_leakyrelu.TRAIN(X_train, y_train, epochs=200, testing=True)\n",
    "nn_leakyrelu.TEST(X_test, y_test)\n",
    "make_plots(df_leakyrelu, [\"accuracy\", \"loss\"], \"leaky_relu\")\n",
    "if savefigs: plt.savefig('figs/nn_leakyrelu.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_sigmoid= nn.NeuralNetwork(test=True, activation_name='sigmoid')\n",
    "df_sigmoid = nn_sigmoid.TRAIN(X_train, y_train, epochs=200, testing=True)\n",
    "nn_leakyrelu.TEST(X_test, y_test)\n",
    "make_plots(df_sigmoid,[\"accuracy\", \"loss\"], \"sigmoid\" )\n",
    "if savefigs: plt.savefig('figs/nn_sigmoid.png', bbox_inches = 'tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = StandardScaler().fit_transform(X_train)\n",
    "pca = PCA(n_components=3)\n",
    "pcax = pca.fit_transform(x)\n",
    "df = pd.DataFrame(data = pcax, columns= ['pc 1', 'pc 2', 'pc 3'])\n",
    "df = pd.concat([df, pd.DataFrame(y_train, columns = ['y'])], axis = 1)\n",
    "\n",
    "x_t = StandardScaler().fit_transform(X_test)\n",
    "pca = PCA(n_components=3)\n",
    "pcax = pca.fit_transform(x_t)\n",
    "df_t = pd.DataFrame(data = pcax, columns= ['pc 1', 'pc 2', 'pc 3'])\n",
    "df_t = pd.concat([df_t, pd.DataFrame(y_test, columns = ['y'])], axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = ['#F59FB8', '#FFCD6D', '#B84543', '#D98E4D', '#8F7CB2']\n",
    "fig, ax = plt.subplots(figsize = (6,6)) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "targets = [0, 1, 2, 3, 4]\n",
    "for target, color in zip(targets,colours):\n",
    "    indicesToKeep = df['y'] == target\n",
    "    ax.scatter(df.loc[indicesToKeep, 'pc 2']\n",
    "               , df.loc[indicesToKeep, 'pc 3']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(NAMES);\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "for target, color in zip(targets,colours):\n",
    "    indicesToKeep = df['y'] == target\n",
    "    ax.scatter(df.loc[indicesToKeep, 'pc 1'], \n",
    "                df.loc[indicesToKeep, 'pc 2'],\n",
    "                df.loc[indicesToKeep, 'pc 3'],\n",
    "                c = color)\n",
    "\n",
    "ax.set_xlabel('Principal Component 1', labelpad=15);\n",
    "ax.set_ylabel('Principal Component 2', labelpad = 15);\n",
    "ax.set_zlabel('Principal Component 3');\n",
    "plt.subplots_adjust(right = 0.2)\n",
    "ax.legend(NAMES);\n",
    "plt.tight_layout();\n",
    "\n",
    "if savefigs:plt.savefig('figs/pca.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.iloc[:, :-1].values\n",
    "Y_train= df.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "X_test = df_t.iloc[:, :-1].values\n",
    "Y_test = df_t.iloc[:, -1].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = dt.DecisionTreeClassifier(min_samples_split=3, max_depth=3)\n",
    "classifier.fit(X_train,Y_train)\n",
    "Y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l = list()\n",
    "for i in range(1,20):\n",
    "    classifier = dt.DecisionTreeClassifier(min_samples_split=3, max_depth=i)\n",
    "    classifier.fit(X_train,Y_train)\n",
    "    Y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    l.append([i, accuracy_score(Y_test, Y_pred)])\n",
    "\n",
    "dt_dataframe =pd.DataFrame(data=l, columns=['depht', 'accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d23f3ceec305a45481076084313530cecc6283a24046b34365f00383ab0a81b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
